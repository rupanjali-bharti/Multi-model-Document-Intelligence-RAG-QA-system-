## ğŸ“š Multi-Modal RAG for Complex Financial & Policy Documents

This repository presents a **Multi-Modal Retrieval-Augmented Generation (RAG) system** designed to answer questions from real-world, information-rich documents such as **IMF Article IV reports**, policy papers, and financial disclosures.

Unlike traditional text-only QA pipelines, this system processes and reasons over **multiple document modalities**, including:

* ğŸ“„ Narrative text
* ğŸ“Š Tables and structured data
* ğŸ“ˆ Charts and figures
* ğŸ–¼ï¸ Scanned images and visual elements
* ğŸ“ Footnotes and references

By combining **multi-modal document parsing**, **vector-based retrieval**, and **large language models**, the system ensures that critical insights embedded in non-textual components are not missed.

### ğŸ” Key Features

* Multi-modal document ingestion (PDFs with text, tables, images)
* Intelligent chunking and embedding across modalities
* Vector databaseâ€“powered retrieval for relevant context
* LLM-based answer generation grounded in retrieved evidence
* Source attribution for transparency and trust
* Designed for financial, economic, and policy analysis use cases

### ğŸš€ Use Cases

* Question answering on IMF, World Bank, and policy reports
* Financial analysis and economic research
* Regulatory and compliance document understanding
* Enterprise knowledge retrieval from complex PDFs

This project demonstrates how **modern LLM applications can move beyond plain text** to deliver accurate, context-aware answers from real-world documents.

---

â­ If you find this useful, consider starring the repository!
